# Sesli Ã‡aÄŸrÄ± AsistanÄ± (Voice Call Assistant)

Bu proje, e-ticaret mÃ¼ÅŸteri hizmetleri iÃ§in geliÅŸtirilmiÅŸ Python tabanlÄ± bir REST API servisidir. KullanÄ±cÄ±lardan gelen sesli sorularÄ± metne Ã§evirir, AI destekli yanÄ±tlar Ã¼retir ve JSON formatÄ±nda dÃ¶ndÃ¼rÃ¼r.

## ğŸ¯ Proje Ã–zeti

**Senaryo**: Bir e-ticaret ÅŸirketinin temel mÃ¼ÅŸteri hizmetleri sorularÄ±nÄ± yanÄ±tlayan sesli asistan prototipi.

**Temel Ä°ÅŸlevler**:
- Sesli sorularÄ± metne Ã§evirme (Speech-to-Text)
- AI destekli mÃ¼ÅŸteri hizmetleri yanÄ±tlarÄ± Ã¼retme
- Ä°steÄŸe baÄŸlÄ±: YanÄ±tlarÄ± seslendirme (Text-to-Speech)

## ğŸ—ï¸ Sistem Mimarisi

```
[Ses DosyasÄ±] â†’ [Whisper STT] â†’ [LLM] â†’ [JSON YanÄ±t] â†’ [TTS (Opsiyonel)]
```

### KullanÄ±lan Teknolojiler

- **Backend Framework**: Flask
- **Speech-to-Text**: OpenAI Whisper
- **LLM**: Mistral-7B / LLaMA (Hugging Face, Together.ai, Replicate)
- **Text-to-Speech**: Coqui XTTS, ElevenLabs (opsiyonel)

## ğŸ“ Proje YapÄ±sÄ±

```
voice-assistant/
â”œâ”€â”€ app.py                 # Ana Flask uygulamasÄ±
â”œâ”€â”€ llm_service.py         # LLM entegrasyonu
â”œâ”€â”€ tts_service.py         # Text-to-Speech servisi
â”œâ”€â”€ config.py              # KonfigÃ¼rasyon ayarlarÄ±
â”œâ”€â”€ requirements.txt       # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ .env.example          # Ã–rnek environment dosyasÄ±
â”œâ”€â”€ README.md             # Bu dosya
â”œâ”€â”€ uploads/              # YÃ¼klenen ses dosyalarÄ± (geÃ§ici)
â”œâ”€â”€ responses/            # Ãœretilen ses yanÄ±tlarÄ±
â””â”€â”€ tests/
    â”œâ”€â”€ test_app.py       # Unit testler
    â””â”€â”€ test_audio/       # Test ses dosyalarÄ±
```

## ğŸš€ Kurulum

### 1. Depoyu KlonlayÄ±n

```bash
git clone https://github.com/username/voice-assistant.git
cd voice-assistant
```

### 2. Virtual Environment OluÅŸturun

```bash
# Python 3.8+ gerekli
python -m venv venv

# Aktivasyon (Windows)
venv\Scripts\activate

# Aktivasyon (Linux/Mac)
source venv/bin/activate
```

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
pip install -r requirements.txt
```

**Not**: Whisper ilk Ã§alÄ±ÅŸmada model dosyalarÄ±nÄ± (~150MB) otomatik indirecektir.

### 4. Environment DeÄŸiÅŸkenlerini AyarlayÄ±n

`.env` dosyasÄ± oluÅŸturun:

```bash
cp .env.example .env
```

`.env` dosyasÄ±nÄ± dÃ¼zenleyin:

```env
# Flask ayarlarÄ±
FLASK_ENV=development
SECRET_KEY=your-secret-key-here

# Whisper model (tiny, base, small, medium, large)
WHISPER_MODEL=base

# LLM API anahtarlarÄ± (opsiyonel - yerel simÃ¼lasyon kullanÄ±labilir)
HUGGINGFACE_API_KEY=your-huggingface-key
TOGETHER_API_KEY=your-together-key
REPLICATE_API_KEY=your-replicate-key

# TTS API anahtarlarÄ± (opsiyonel)
ELEVENLABS_API_KEY=your-elevenlabs-key

# Sunucu ayarlarÄ±
PORT=8000
DEBUG=true
```

### 5. Servisi BaÅŸlatÄ±n

```bash
python app.py
```

Servis `http://localhost:5000` adresinde Ã§alÄ±ÅŸmaya baÅŸlayacaktÄ±r.

## ğŸ“¡ API KullanÄ±mÄ±

### Ana Endpoint: `/ask_assistant`

**Method**: POST  
**Content-Type**: multipart/form-data

**Parametre**:
- `audio_file`: Ses dosyasÄ± (.wav, .mp3, .mp4, .m4a, .flac, .ogg)

**Ã–rnek Ä°stek**:

```bash
curl -X POST \
  http://localhost:5000/ask_assistant \
  -F "audio_file=@test_audio.wav"
```

**Ã–rnek YanÄ±t**:

```json
{
  "transcribed_text": "SipariÅŸim ne zaman gelecek?",
  "assistant_response": "SipariÅŸiniz kargoya verilmiÅŸ olup, 2-4 iÅŸ gÃ¼nÃ¼ iÃ§inde teslim edilmesi beklenmektedir.",
  "response_audio_url": "/responses/response_12345.wav"
}
```

### DiÄŸer Endpointler

#### SaÄŸlÄ±k KontrolÃ¼
```bash
GET /health
```

#### Ana Sayfa
```bash
GET /
```

#### Ses YanÄ±tlarÄ±
```bash
GET /responses/<filename>
```

## ğŸ”§ DetaylÄ± KonfigÃ¼rasyon

### Whisper Model SeÃ§imi

Whisper modelleri performans ve kalite aÃ§Ä±sÄ±ndan farklÄ±lÄ±k gÃ¶sterir:

- `tiny`: En hÄ±zlÄ±, dÃ¼ÅŸÃ¼k kalite (~39 MB)
- `base`: Dengeli performans (~74 MB) **[VarsayÄ±lan]**
- `small`: Ä°yi kalite (~244 MB)
- `medium`: YÃ¼ksek kalite (~769 MB)
- `large`: En iyi kalite (~1550 MB)

### LLM Entegrasyonu

#### 1. Hugging Face Integration

```python
# .env dosyasÄ±na ekleyin
HUGGINGFACE_API_KEY=your-token-here
```

Hugging Face hesabÄ±nÄ±zdan Ã¼cretsiz API token alabilirsiniz.

#### 2. Together.ai Integration

```python
# .env dosyasÄ±na ekleyin
TOGETHER_API_KEY=your-api-key-here
```

Together.ai'dan API anahtarÄ± alÄ±n ve Mistral modellerine eriÅŸim saÄŸlayÄ±n.

#### 3. Replicate Integration

```python
# .env dosyasÄ±na ekleyin
REPLICATE_API_KEY=your-api-token-here
```

### TTS (Text-to-Speech) KonfigÃ¼rasyonu

#### ElevenLabs (Ã–nerilen)

```python
# .env dosyasÄ±na ekleyin
ELEVENLABS_API_KEY=your-api-key-here
```

#### Coqui XTTS (Ãœcretsiz Alternatif)

```bash
pip install TTS
```

Yerel Coqui XTTS kurulumu iÃ§in `tts_service.py` dosyasÄ±ndaki yorum satÄ±rlarÄ±nÄ± aÃ§Ä±n.

## ğŸ³ Docker ile Ã‡alÄ±ÅŸtÄ±rma

### Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Sistem baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kle
RUN apt-get update && apt-get install -y \
    ffmpeg \
    git \
    && rm -rf /var/lib/apt/lists/*

# Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kle
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Uygulama dosyalarÄ±nÄ± kopyala
COPY . .

# Gerekli klasÃ¶rleri oluÅŸtur
RUN mkdir -p uploads responses

# Port aÃ§
EXPOSE 5000

# UygulamayÄ± baÅŸlat
CMD ["python", "app.py"]
```

### Docker Compose

```yaml
version: '3.8'

services:
  voice-assistant:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - WHISPER_MODEL=base
    volumes:
      - ./uploads:/app/uploads
      - ./responses:/app/responses
    restart: unless-stopped
```

Ã‡alÄ±ÅŸtÄ±rma:

```bash
docker-compose up -d
```

## ğŸ§ª Test Etme

### Unit Testler

```bash
# Testleri Ã§alÄ±ÅŸtÄ±r
python -m pytest tests/ -v

# Coverage ile
pip install pytest-cov
python -m pytest tests/ --cov=. --cov-report=html
```

### Manuel Test

```bash
# SaÄŸlÄ±k kontrolÃ¼
curl http://localhost:5000/health

# Ses dosyasÄ± ile test
curl -X POST \
  http://localhost:5000/ask_assistant \
  -F "audio_file=@test_audio.wav"
```

### Test Ses DosyasÄ± OluÅŸturma

Python ile test ses dosyasÄ±:

```python
import numpy as np
import soundfile as sf

# 3 saniyelik test sesi oluÅŸtur
sample_rate = 16000
duration = 3
t = np.linspace(0, duration, int(sample_rate * duration))
audio = 0.3 * np.sin(2 * np.pi * 440 * t)  # 440 Hz ton

sf.write('test_audio.wav', audio, sample_rate)
```

## ğŸš€ Production Deployment

### Gunicorn ile

```bash
# Gunicorn yÃ¼kle
pip install gunicorn

# Servisi baÅŸlat
gunicorn --bind 0.0.0.0:5000 --workers 4 app:app
```

### Nginx KonfigÃ¼rasyonu

```nginx
server {
    listen 80;
    server_name your-domain.com;
    
    client_max_body_size 20M;
    
    location / {
        proxy_pass http://127.0.0.1:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
}
```

### Environment Variables (Production)

```env
FLASK_ENV=production
SECRET_KEY=very-secure-random-key
WHISPER_MODEL=small
DEBUG=false
PORT=5000

# API Keys
HUGGINGFACE_API_KEY=your-production-key
TOGETHER_API_KEY=your-production-key
ELEVENLABS_API_KEY=your-production-key
```

## ğŸ” Ã–rnek KullanÄ±m SenaryolarÄ±

### 1. SipariÅŸ Durumu Sorgulama

**Ses Girdi**: "Merhaba, sipariÅŸim nerede?"  
**AI YanÄ±t**: "SipariÅŸiniz kargoya verilmiÅŸ olup, 2-4 iÅŸ gÃ¼nÃ¼ iÃ§inde teslim edilmesi beklenmektedir."

### 2. ÃœrÃ¼n Ä°adesi

**Ses Girdi**: "AldÄ±ÄŸÄ±m Ã¼rÃ¼nÃ¼ iade etmek istiyorum."  
**AI YanÄ±t**: "ÃœrÃ¼n iade iÅŸleminizi web sitemizden baÅŸlatabilirsiniz. Ä°ade sÃ¼reci 14 gÃ¼n iÃ§inde tamamlanÄ±r."

### 3. Kargo Bilgisi

**Ses Girdi**: "Kargo ne zaman gelir?"  
**AI YanÄ±t**: "Kargo sÃ¼remiz ÅŸehir iÃ§i 1-2 iÅŸ gÃ¼nÃ¼, ÅŸehir dÄ±ÅŸÄ± 2-4 iÅŸ gÃ¼nÃ¼dÃ¼r."

## ğŸ› ï¸ GeliÅŸtirme NotlarÄ±

### Whisper Model Optimizasyonu

```python
# Daha hÄ±zlÄ± transkripsiyon iÃ§in
import whisper

model = whisper.load_model("base")
result = model.transcribe("audio.wav", fp16=False, language="tr")
```

### LLM Response GeliÅŸtirme

Daha akÄ±llÄ± yanÄ±tlar iÃ§in `llm_service.py`'de:

1. Daha fazla anahtar kelime ekleyin
2. Context-aware yanÄ±tlar geliÅŸtirin
3. GerÃ§ek e-ticaret API'leri entegre edin

### Performans Optimizasyonu

```python
# Async iÅŸleme iÃ§in
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor(max_workers=4)

# Background task olarak TTS
future = executor.submit(tts_service.generate_audio, text, output_path)
```

## ğŸ” GÃ¼venlik

### API Rate Limiting

```python
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app,
    key_func=get_remote_address,
    default_limits=["100 per hour"]
)

@app.route('/ask_assistant', methods=['POST'])
@limiter.limit("10 per minute")
def ask_assistant():
    # ...
```

### File Validation

```python
import magic

def validate_audio_file(file_path):
    """Validate uploaded file is actually audio"""
    file_type = magic.from_file(file_path, mime=True)
    return file_type.startswith('audio/')
```

## ğŸ“Š Monitoring ve Logging

### Structured Logging

```python
import structlog

logger = structlog.get_logger()

logger.info("Processing request", 
           user_id=user_id, 
           file_size=file_size,
           transcription_time=duration)
```

### Health Check Endpoint

`/health` endpoint servise ÅŸunlarÄ± kontrol eder:
- Whisper model durumu
- Disk alanÄ±
- API baÄŸlantÄ±larÄ±

## ğŸŒ Cloud Deployment SeÃ§enekleri

### 1. Google Colab

```python
# Colab'da Ã§alÄ±ÅŸtÄ±rmak iÃ§in
!pip install -r requirements.txt
!python app.py

# Ngrok ile public URL
!pip install pyngrok
from pyngrok import ngrok
public_url = ngrok.connect(5000)
```

### 2. Replicate Deployment

```python
# replicate.yaml
version: "1"
image: "python:3.9"
predict: "predict.py:predict"
```

### 3. Together.ai Integration

```python
import together

together.api_key = "your-key"

response = together.Complete.create(
    prompt=f"Customer service response to: {text}",
    model="mistralai/Mistral-7B-Instruct-v0.1",
    max_tokens=150
)
```

## ğŸ¨ Frontend Entegrasyonu

### JavaScript Client Ã–rneÄŸi

```javascript
async function sendAudioToAssistant(audioBlob) {
    const formData = new FormData();
    formData.append('audio_file', audioBlob, 'recording.wav');
    
    try {
        const response = await fetch('/ask_assistant', {
            method: 'POST',
            body: formData
        });
        
        const result = await response.json();
        
        // Transkripsiyon gÃ¶ster
        document.getElementById('transcription').textContent = result.transcribed_text;
        
        // AI yanÄ±tÄ±nÄ± gÃ¶ster
        document.getElementById('response').textContent = result.assistant_response;
        
        // Ses yanÄ±tÄ±nÄ± Ã§al (varsa)
        if (result.response_audio_url) {
            const audio = new Audio(result.response_audio_url);
            audio.play();
        }
        
    } catch (error) {
        console.error('Error:', error);
    }
}
```

### React Component Ã–rneÄŸi

```jsx
import React, { useState } from 'react';

const VoiceAssistant = () => {
    const [recording, setRecording] = useState(false);
    const [response, setResponse] = useState(null);
    
    const handleRecording = async (audioBlob) => {
        const formData = new FormData();
        formData.append('audio_file', audioBlob);
        
        const result = await fetch('/ask_assistant', {
            method: 'POST',
            body: formData
        });
        
        const data = await result.json();
        setResponse(data);
    };
    
    return (
        <div>
            <button onClick={startRecording}>
                {recording ? 'KaydÄ± Durdur' : 'KonuÅŸmaya BaÅŸla'}
            </button>
            
            {response && (
                <div>
                    <p><strong>AnladÄ±ÄŸÄ±m:</strong> {response.transcribed_text}</p>
                    <p><strong>YanÄ±tÄ±m:</strong> {response.assistant_response}</p>
                </div>
            )}
        </div>
    );
};
```

## ğŸ“ˆ Performans ve Ã–lÃ§eklendirme

### Benchmark SonuÃ§larÄ±

| Ä°ÅŸlem | SÃ¼re | Kaynak KullanÄ±mÄ± |
|-------|------|------------------|
| Whisper (base) | ~2-5s | 500MB RAM |
| LLM Response | ~1-3s | 200MB RAM |
| TTS Generation | ~3-8s | 300MB RAM |

### Ã–lÃ§eklendirme Ã–nerileri

1. **Redis Cache**: SÄ±k sorulan sorularÄ±n yanÄ±tlarÄ±nÄ± Ã¶nbelleÄŸe alÄ±n
2. **Queue System**: Celery ile background processing
3. **Load Balancing**: Nginx ile multiple worker instance
4. **GPU Support**: CUDA destekli Whisper ve LLM

## ğŸ”§ Sorun Giderme

### YaygÄ±n Sorunlar

#### 1. Whisper Model YÃ¼klenmiyor

```bash
# Manuel model indirme
python -c "import whisper; whisper.load_model('base')"
```

#### 2. Ses DosyasÄ± Format HatasÄ±

```python
# FFmpeg ile format dÃ¶nÃ¼ÅŸtÃ¼rme
import subprocess

subprocess.run([
    'ffmpeg', '-i', 'input.mp3', 
    '-ar', '16000', '-ac', '1', 
    'output.wav'
])
```

#### 3. Memory HatasÄ±

```python
# Model boyutunu kÃ¼Ã§Ã¼ltÃ¼n
WHISPER_MODEL=tiny

# Veya swap alanÄ± artÄ±rÄ±n
sudo swapon --show
sudo fallocate -l 2G /swapfile
```

### Log Seviyesi Ayarlama

```python
import logging

# Debug iÃ§in
logging.basicConfig(level=logging.DEBUG)

# Production iÃ§in
logging.basicConfig(level=logging.WARNING)
```

## ğŸ“ API DokÃ¼mantasyonu

### OpenAPI/Swagger Spec

```yaml
openapi: 3.0.0
info:
  title: Voice Call Assistant API
  version: 1.0.0
  description: E-ticaret mÃ¼ÅŸteri hizmetleri sesli asistan

paths:
  /ask_assistant:
    post:
      summary: Sesli soru sorma
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                audio_file:
                  type: string
                  format: binary
      responses:
        200:
          description: BaÅŸarÄ±lÄ± yanÄ±t
          content:
            application/json:
              schema:
                type: object
                properties:
                  transcribed_text:
                    type: string
                  assistant_response:
                    type: string
                  response_audio_url:
                    type: string
```

## ğŸ§ª Test SenaryolarÄ±

### Test KomutlarÄ±

```bash
# SipariÅŸ durumu testi
curl -X POST http://localhost:5000/ask_assistant \
  -F "audio_file=@tests/audio/order_status.wav"

# Ä°ade testi  
curl -X POST http://localhost:5000/ask_assistant \
  -F "audio_file=@tests/audio/return_request.wav"

# Kargo bilgisi testi
curl -X POST http://localhost:5000/ask_assistant \
  -F "audio_file=@tests/audio/shipping_info.wav"
```

### Load Testing

```bash
# Apache Bench ile
ab -n 100 -c 10 -p test_audio.wav -T multipart/form-data \
   http://localhost:5000/ask_assistant

# Locust ile
pip install locust
locust -f tests/load_test.py --host=http://localhost:5000
```

## ğŸ“š GeliÅŸmiÅŸ Ã–zellikler

### 1. Ã‡oklu Dil DesteÄŸi

```python
# Whisper otomatik dil algÄ±lama
result = whisper_model.transcribe(audio_path, language=None)
detected_language = result["language"]
```

### 2. KonuÅŸma Analizi

```python
# Duygu analizi iÃ§in
from transformers import pipeline

sentiment_analyzer = pipeline(
    "sentiment-analysis",
    model="savasy/bert-base-turkish-sentiment-cased"
)

sentiment = sentiment_analyzer(transcribed_text)
```

### 3. Conversation History

```python
# Redis ile konuÅŸma geÃ§miÅŸi
import redis

r = redis.Redis(host='localhost', port=6379, db=0)

def save_conversation(user_id, question, response):
    conversation = {
        'timestamp': datetime.now().isoformat(),
        'question': question,
        'response': response
    }
    r.lpush(f"conversations:{user_id}", json.dumps(conversation))
```

## ğŸ”„ SÃ¼rekli Ä°yileÅŸtirme

### Model Fine-tuning

```python
# Whisper fine-tuning iÃ§in domain-specific data
# Custom e-ticaret terimleri ile model eÄŸitimi

# LLM fine-tuning
# GerÃ§ek mÃ¼ÅŸteri hizmetleri konuÅŸmalarÄ± ile eÄŸitim
```

### A/B Testing

```python
# FarklÄ± LLM modellerini test etme
import random

models = ["mistral-7b", "llama-7b", "gpt-3.5-turbo"]
selected_model = random.choice(models)
```

## ğŸ“ Destek ve Ä°letiÅŸim

### GeliÅŸtirici NotlarÄ±

- **Proje YÃ¶neticisi**: Mehmetcan ArapisaoÄŸlu
- **Repository**: https://github.com/username/voice-assistant

**Son GÃ¼ncelleme**: 1 EylÃ¼l 2025  
**Versiyon**: 1.0.0
